{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K4cp3rski/ML_FUW/blob/master/Cybi%C5%84ski_02_zadanie_domowe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYtv4ZSbTx5X"
      },
      "source": [
        "# Praca domowa I, zadanie II\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaX60EphVC74"
      },
      "source": [
        "## Treść"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4_wGX3_coFa"
      },
      "source": [
        "### Wstęp fabularny"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJlu3kmQchcE"
      },
      "source": [
        "Wyobraź sobie, że jesteś pracownikiem w firmie sprzedającej kompleksową usługę tworzenia wizerunków medialnych. Oddział, w którym pracujesz obsługuje ważnego klienta działającego w branży gier i usług cyfrowych.\n",
        "\n",
        "Twoim zadaniem jest przygotować model uczenia maszynowego, który określać będzie nastawienie emocjonalne postów z Twittera. Zespół odpowiadający za zbieranie danych właśnie dostarczył zestaw danych dla Ciebie.\n",
        "\n",
        "Do tej pory klasyfikowaniem nastrojów z twittów zajmował się zespół ekspertów. Rozwiązanie takie jest bardzo wolne i drogie, a dokładność ekspertów wynosi tylko 95%. Dlatego zarząd firmy zlecił wdrożenie modelu uczenia maszynowego.\n",
        "\n",
        "Twój model stanowić będzie jedynie część większego produktu oferowanego przez Twoją firmę. Wyniki Twojego modelu będą bezpośrednio wykorzystywane przez następny zespół, którego zadaniem jest przygotować kolejny model uczenia maszynowego przewidujący reakcje opinii publicznej na posty klienta.\n",
        "\n",
        "Prace zespołu, który korzystać będzie z Twojego modelu są już bardzo zaawansowane, dlatego nie może on pozwolić sobie na żadne dodatkowe zmiany w swoim projekcie. Absolutnie konieczne jest, aby Twój model przyporządkowywał posty do jednej z trzech klas 'Positive', 'Negative', 'Neutral' lub analogicznych. Posty nie na temat powinny być klasyfikowane jako 'Neutral'.\n",
        "\n",
        "Notebook z Twoim projektem będzie oglądał Twój szef, więc koniecznie zadbaj, żeby znalazły się w nim najważniejsze przemyślenia, a rysunki były ładne.\n",
        "\n",
        "Powodzenia 🦾"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRk5odT-VpHl"
      },
      "source": [
        "### Polecenia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqep_SopVL6B"
      },
      "source": [
        "1. Wstępna obróbka danych:\n",
        "\n",
        " - załaduj zbiór treningowy i testowy,\n",
        " - usuń wiersze o brakujących elementach,\n",
        " - w kolumnie `sentiment` zamień wartości `'Irrelevant'` na `'Neutral'`.\n",
        "\n",
        "1. Wykonaj wizualizacje danych:\n",
        "\n",
        " - histogram tematów twittów (`entity`),\n",
        " - histogram nastawień (`sentiment`),\n",
        " - najczęściej padających słów w treści twittów (`content`).\n",
        "\n",
        "1. Przygotuj dane:\n",
        "\n",
        " - przygotuj zbiór cech poprzez wektoryzacje kolumny `content`, \n",
        " - przygotuj etykiety poprzez zakodowanie tekstowych wartości w kolumnie `sentiment` do postaci liczbowej.\n",
        "\n",
        "  Następnie wytrenuj naiwny model bayesowski. Sprawdź działanie modelu na kilku własnoręcznie napisanych wiadomościach. \n",
        "\n",
        "1. Wytrenuj modele:\n",
        " - naiwny bayesowski,\n",
        " - liniowy SVM,\n",
        " - regresji logistycznej,\n",
        " - drzewo decyzyjne.\n",
        "\n",
        "  Sprawdź model na danych treningowych (walidacja krzyżowa) i testowych, następnie wybierz najlepszy model. Uzasadnij swój wybór.\n",
        "  \n",
        "1. Zespół ekspertów ręcznie klasyfikuje dane z dokładnością 95%. Porównaj z nimi swój model i napisz jakie są przewagi Twojego modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZpaDghkU_B7"
      },
      "source": [
        "### Zbiór danych\n",
        "\n",
        "Zbiór danych został przygotowany na podstawie zbioru [Twitter Sentiment Analysis](https://www.kaggle.com/jp797498e/twitter-entity-sentiment-analysis) i składa się z dwóch plików:\n",
        "-  `twitter_training.csv` - zbiór treningowy,\n",
        "- `twitter_validation.csv` - zbiór testowy.\n",
        "\n",
        "Archiwum z plikami można pobrać z [dysku google](https://drive.google.com/file/d/1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB/view?usp=sharing) lub odkomentowując poniższe linie:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "lrlti4Zk4Lhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlvbsKdVU0hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a490b45-ff58-41ea-87af-d666b9d66aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB\n",
            "To: /content/twitter.zip\n",
            "\r  0% 0.00/2.07M [00:00<?, ?B/s]\r100% 2.07M/2.07M [00:00<00:00, 133MB/s]\n",
            "Archive:  twitter.zip\n",
            "  inflating: twitter_training.csv    \n",
            "  inflating: twitter_validation.csv  \n"
          ]
        }
      ],
      "source": [
        "# ! pip install gdown\n",
        "! gdown https://drive.google.com/uc?id=1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB\n",
        "! unzip twitter.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95mTOShAjGji"
      },
      "outputs": [],
      "source": [
        "# !pip install wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGrsOK5pT1Xw"
      },
      "source": [
        "# Rozwiązanie"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impoty \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TERrt4LEZdp",
        "outputId": "df9a7605-bd65-444b-fd13-00b7592cc7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ładowanie danych"
      ],
      "metadata": {
        "id": "de84o_Yt-3LL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ0m63_gU41z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3b79e8-f07c-4f39-beef-cae89a5a7e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zainstalowana wersja scikit-learn: 1.0.1.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "print('Zainstalowana wersja scikit-learn: {}.'.format(sklearn.__version__))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10) # aby wykresy w Colabie były większe\n",
        "\n",
        "import numpy as np\n",
        "from scipy import diag, interp\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6Ykp7XDRlF5"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('twitter_training.csv')\n",
        "test_data = pd.read_csv('twitter_validation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7rWWbBA9wTr"
      },
      "source": [
        "Jak widzimy globalnie (Obrazek 1) klasy są w miare zbalansowane, liczebność nie różni się więcej jak 2-krotnie. W związku z tym wydaje się, że nie ma potrzeby sztucznego wyrównywania ich liczebności i można przejść do dalszego etapu preprocessingu danych"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing danych"
      ],
      "metadata": {
        "id": "uNbac6Dd_Do3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zmieniamy labelki na integerowe"
      ],
      "metadata": {
        "id": "FYYpHtacAvIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMIHVxWiR4s8"
      },
      "outputs": [],
      "source": [
        "# Przydzielamy klasom integerowe labelki\n",
        "\n",
        "# Neutral = Class 0\n",
        "train_data.loc[train_data['sentiment'] == 'Positive', 'sentiment'] = 0\n",
        "# Positive = Class 1\n",
        "train_data.loc[train_data['sentiment'] == 'Neutral', 'sentiment'] = 1\n",
        "# Negative = Class 2\n",
        "train_data.loc[train_data['sentiment'] == 'Negative', 'sentiment'] = 2\n",
        "# Irrelevant = Class 1\n",
        "train_data.loc[train_data['sentiment'] == 'Irrelevant', 'sentiment'] = 1\n",
        "\n",
        "# A teraz to samo dla zbiotu testowego\n",
        "\n",
        "# Neutral = Class 0\n",
        "test_data.loc[test_data['sentiment'] == 'Positive', 'sentiment'] = 0\n",
        "# Positive = Class 1\n",
        "test_data.loc[test_data['sentiment'] == 'Neutral', 'sentiment'] = 1\n",
        "# Negative = Class 2\n",
        "test_data.loc[test_data['sentiment'] == 'Negative', 'sentiment'] = 2\n",
        "# Irrelevant = Class 1\n",
        "test_data.loc[test_data['sentiment'] == 'Irrelevant', 'sentiment'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYH-7SsoXZy1"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop(columns='id')\n",
        "test_data = test_data.drop(columns='id')\n",
        "\n",
        "train_data = train_data.rename(columns={'sentiment':'Class'})\n",
        "test_data = test_data.rename(columns={'sentiment':'Class'})\n",
        "\n",
        "# Pozbywamy się wierszy z niepełnymi informacjani (NaN)\n",
        "train_data = train_data.dropna(axis='rows', how='all', thresh=int(train_data.shape[1]))\n",
        "test_data = test_data.dropna(axis='rows', how='all', thresh=int(test_data.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wizualizacja danych, oraz najczęściej występujących słów w tweetach danych kategorii"
      ],
      "metadata": {
        "id": "dkfna3Sm_SYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Wizualizacja danych\n",
        "\n",
        "# f = sns.countplot(x='sentiment', data=train_data)\n",
        "# h = sns.catplot(y='entity', hue='sentiment', data=train_data, kind='count', height=20, aspect=1)\n",
        "# g = sns.catplot(x='sentiment', col='entity' , col_wrap=4, kind='count', data=train_data, height=4.5, aspect=1.2)\n",
        "# i = sns.catplot(y='entity', data=train_data, height=20, kind='count')\n",
        "\n",
        "# (g.set_axis_labels(\"\", \"Tweet count\")\n",
        "# .set_xticklabels([\"Positive\", \"Neutral\", \"Negative\", 'Irrelevant'])\n",
        "# .set_titles(\"{col_name}\")\n",
        "# .despine(left=True))  "
      ],
      "metadata": {
        "id": "fDucnE6j_P8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfeT0MkjjLdz"
      },
      "outputs": [],
      "source": [
        "# # Zobaczmy sobie najczęściej występujące słowa w klasach słów pozytywnych, neutralnych, negatywnych i irrelevant\n",
        "\n",
        "# import wordcloud\n",
        "# from wordcloud import WordCloud\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Neutralne tweety\n",
        "# neutral_list = list(map(str, train_data [train_data['Class'] == 0]['content']))\n",
        "\n",
        "# neutral_words = \" \".join(neutral_list)\n",
        "# neutral_plot = WordCloud(width = 512, height = 512).generate(neutral_words)\n",
        "\n",
        "# # Pozytywne tweety\n",
        "# positive_list = list(map(str, train_data [train_data['Class'] == 1]['content']))\n",
        "\n",
        "# positive_words = \" \".join(positive_list)\n",
        "# positive_plot = WordCloud(width = 512, height = 512).generate(positive_words)\n",
        "\n",
        "# # Negatywne tweety\n",
        "# negative_list = list(map(str, train_data [train_data['Class'] == 2]['content']))\n",
        "\n",
        "# negative_words = \" \".join(negative_list)\n",
        "# negative_plot = WordCloud(width = 512, height = 512).generate(negative_words)\n",
        "\n",
        "# plt.figure(figsize=(10,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz2VYWJ-6KzW"
      },
      "outputs": [],
      "source": [
        "# images = [neutral_plot, positive_plot, negative_plot]\n",
        "# image_names = ['neutral', 'positive', 'negative']\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.suptitle('Most frequent words in tweets class-wise',y = 0.95, x = 0.4, weight='heavy', size='xx-large')\n",
        "# columns = 4\n",
        "# for i, image in enumerate(images):\n",
        "#     plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "#     plt.axis('off')\n",
        "#     plt.title(image_names[i])\n",
        "#     plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rozdzielamy na dane wejściowe i wyjściowe"
      ],
      "metadata": {
        "id": "Yigl7DLp_cHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po tym zmieniamy komórki ze stringami na floaty za pomocą Vectorizera"
      ],
      "metadata": {
        "id": "37zZNe0A_n_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO2ymm3i8gCy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = train_data.drop(columns='Class')\n",
        "y_train = np.asarray(train_data['Class']).reshape(-1, 1).ravel()\n",
        "y_train = y_train.astype('int')\n",
        "\n",
        "X_test = test_data.drop(columns='Class')\n",
        "y_test = np.asarray(test_data['Class']).reshape(-1, 1).ravel()\n",
        "y_test = y_test.astype('int')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnOPvA2R8q2_"
      },
      "source": [
        "Teraz jak już mamy zwizualizowane dane, to przekodujmy je na język zrozumiały przez maszynę, tj. wektory cech.\n",
        "\n",
        " W tym celu użyjemy funkcji *TfidfVectorizer*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-2GLc05AoU4"
      },
      "outputs": [],
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['content']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSEn5jw--_rf"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych\n",
        "\n",
        "vectorizer_text = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW6D6c7Z_ul3",
        "outputId": "7d79af1f-5e8e-4bee-f619-2484179edf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dane treningowe: n_samples: 73996, n_features: 31100\n"
          ]
        }
      ],
      "source": [
        "print(\"Dane treningowe: n_samples: %d, n_features: %d\" % X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii78Uj9REIrm"
      },
      "source": [
        "Odwrotne mapowanie cech na słowa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPfcl7zBAMT0"
      },
      "outputs": [],
      "source": [
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDYYgsO4HxKX"
      },
      "source": [
        "### Aby polepszyć wyniki klasyfikatorów poddajemy dane stemmingowi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRzg4o6IVyu"
      },
      "source": [
        "Jednak jako, że jedna z naszych kolumn zawiera tylko nazwy gier/tematów o których jest pisane, to stemmingowi chcemy poddać jedynie kolumnę z treścią tweetów, bo to tam szukanie słów o wspólnych korzeniach znaczeniowych będzie mieć znaczenie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dP3zZ0aJKl77"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "words = stopwords.words(\"english\")\n",
        "train_data['cleaned'] = train_data['content'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
        "test_data['cleaned'] = test_data['content'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Byw6-3Kdg3k"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqwF1_TlIIZj"
      },
      "outputs": [],
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['cleaned']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['cleaned']\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych wraz ze stemmingiem\n",
        "\n",
        "vectorizer_text =  TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2)) # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n",
        "\n",
        "\n",
        "\n",
        "# <--- !! ---> #\n",
        "\n",
        "\n",
        "\n",
        "# # Odwrotne mapowanie tweetów na słowa\n",
        "\n",
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UelXhyVHdgUg",
        "outputId": "4a72e48d-d73d-4f26-d0bf-a7939c826b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.939\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92       277\n",
            "           1       0.95      0.96      0.95       457\n",
            "           2       0.93      0.93      0.93       266\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.94      0.93      0.94      1000\n",
            "weighted avg       0.94      0.94      0.94      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[254  14   9]\n",
            " [ 10 438   9]\n",
            " [  9  10 247]]\n"
          ]
        }
      ],
      "source": [
        "model_NB = MultinomialNB()\n",
        "model_NB.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_NB.predict(X_test)\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWYO9AXDgj-K"
      },
      "source": [
        "*** Inspiracja kodem z https://towardsdatascience.com/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5z5foCldsFd",
        "outputId": "88b3821b-1517-4a21-b3ff-53d8f1adecf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 1.000\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       277\n",
            "           1       1.00      1.00      1.00       457\n",
            "           2       1.00      1.00      1.00       266\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[277   0   0]\n",
            " [  0 457   0]\n",
            " [  0   0 266]]\n",
            "MCC =  1.000, Balanced ACC = 1.000  \n"
          ]
        }
      ],
      "source": [
        "# instead of doing these steps one at a time, we can use a pipeline to complete them all at once\n",
        "pipeline = Pipeline([('chi',  SelectKBest(chi2, k=1200)),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "# fitting our model and save it in a pickle for later use\n",
        "model_NB = pipeline.fit(X_train, y_train)\n",
        "with open('Multinomial.pickle', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "y_pred = np.array(y_test)\n",
        "\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
        "BACC = metrics.balanced_accuracy_score(y_test, y_pred)\n",
        "print('MCC =  {m:.3f}, Balanced ACC = {b:.3f}  '.format(m=MCC, b=BACC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNgQ5EsoftTk"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCatqNVlhBZw"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, StandardScaler\n",
        "model_SVM = LinearSVC(C=1E-2, dual=False, max_iter=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td3aryyPhDcG"
      },
      "source": [
        "Do SVM już musimy bezwzględnie przeskalować nasze dane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJHTTOCTh-fd"
      },
      "outputs": [],
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['cleaned']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['cleaned']\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych wraz ze stemmingiem\n",
        "\n",
        "vectorizer_text =  TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2)) # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n",
        "\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# <--- !! ---> #\n",
        "\n",
        "\n",
        "\n",
        "# # Odwrotne mapowanie tweetów na słowa\n",
        "\n",
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejtax03Gf2Wx",
        "outputId": "73268bbb-4648-490b-e3ee-69be40b4be9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=0.01, dual=False, max_iter=10000)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "# Fitowanie modelu (trwa ok 3 min)\n",
        "model_SVM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVBxlbTPNhow",
        "outputId": "8e3beba1-7907-4bbb-8947-2a7d5ad2018a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.975\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       277\n",
            "           1       0.98      0.98      0.98       457\n",
            "           2       0.97      0.97      0.97       266\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.98      0.97      0.97      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[267   4   6]\n",
            " [  4 450   3]\n",
            " [  2   6 258]]\n",
            "MCC =  0.961, Balanced ACC = 0.973  \n"
          ]
        }
      ],
      "source": [
        "# Walidacja \n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = model_SVM.predict(X_test)\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
        "BACC = metrics.balanced_accuracy_score(y_test, y_pred)\n",
        "print('MCC =  {m:.3f}, Balanced ACC = {b:.3f}  '.format(m=MCC, b=BACC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muNxoVJmtvYe"
      },
      "source": [
        "Dostajemy bardzo dobry wynik, skuteczność na poziomie 97%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz3j0lMrtYsA"
      },
      "source": [
        "## Regresja Logistyczna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxDvZTa-t7Zd",
        "outputId": "c668173c-65ca-451d-a5f9-975bfff5bbf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=10000)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Tu znowu model liczy się ok 3 min\n",
        "model_log = LogisticRegression(solver = 'lbfgs', max_iter=10000)\n",
        "model_log.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxNwr1LPv54m"
      },
      "outputs": [],
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['cleaned']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['cleaned']\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych wraz ze stemmingiem\n",
        "\n",
        "vectorizer_text =  TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2)) # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n",
        "\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# <--- !! ---> #\n",
        "\n",
        "\n",
        "\n",
        "# # Odwrotne mapowanie tweetów na słowa\n",
        "\n",
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG-o5Wuju3mY",
        "outputId": "0498ad54-5abc-4e81-b267-2d10ffc4aa05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.974\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       277\n",
            "           1       0.98      0.98      0.98       457\n",
            "           2       0.96      0.97      0.97       266\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.97      0.97      0.97      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[267   4   6]\n",
            " [  5 448   4]\n",
            " [  2   5 259]]\n",
            "MCC =  0.960, Balanced ACC = 0.973  \n"
          ]
        }
      ],
      "source": [
        "y_pred = model_log.predict(X_test)  \n",
        "\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
        "BACC = metrics.balanced_accuracy_score(y_test, y_pred)\n",
        "print('MCC =  {m:.3f}, Balanced ACC = {b:.3f}  '.format(m=MCC, b=BACC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr3VyiT2yfwD"
      },
      "source": [
        "## DecissionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2UslwUeyi2W"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "\n",
        "# Deklarujemy klasyfikator\n",
        "model_tree = tree.DecisionTreeClassifier()\n",
        "# Fitujemy do danych treningowych\n",
        "model_tree = model_tree.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvSOoiM5zHOy"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import Image \n",
        "\n",
        "# from six import StringIO\n",
        "# import pydot \n",
        "\n",
        "# dot_data = StringIO()  \n",
        "# tree.export_graphviz(clf, out_file=dot_data,  \n",
        "                         # class_names=['Neutral', 'Positive', 'Negative'],  \n",
        "                         # filled=True, rounded=True,  \n",
        "                         # special_characters=True) \n",
        "# graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
        "# Image(graph[0].create_png())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_tree.predict(X_test)  \n",
        "\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "MCC = metrics.matthews_corrcoef(y_test, y_pred)\n",
        "BACC = metrics.balanced_accuracy_score(y_test, y_pred)\n",
        "print('MCC =  {m:.3f}, Balanced ACC = {b:.3f}  '.format(m=MCC, b=BACC))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-QAj8bP4Bkz",
        "outputId": "cdc2ec79-d8d8-4822-bf71-5d21ca06e74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.923\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91       277\n",
            "           1       0.94      0.92      0.93       457\n",
            "           2       0.90      0.95      0.93       266\n",
            "\n",
            "    accuracy                           0.92      1000\n",
            "   macro avg       0.92      0.92      0.92      1000\n",
            "weighted avg       0.92      0.92      0.92      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[250  19   8]\n",
            " [ 18 420  19]\n",
            " [  5   8 253]]\n",
            "MCC =  0.881, Balanced ACC = 0.924  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Elapsed time\\n--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "RwRVasC-4JW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bez CV\n",
        "\n",
        "Elapsed time\n",
        "--- 472.361172914505 seconds ---"
      ],
      "metadata": {
        "id": "VzuVKqZX9rcf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Cybiński_02_zadanie_domowe.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}