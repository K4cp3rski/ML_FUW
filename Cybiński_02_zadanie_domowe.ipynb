{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cybiński_02_zadanie_domowe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K4cp3rski/ML_FUW/blob/master/Cybi%C5%84ski_02_zadanie_domowe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praca domowa I, zadanie II\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sYtv4ZSbTx5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treść"
      ],
      "metadata": {
        "id": "NaX60EphVC74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wstęp fabularny"
      ],
      "metadata": {
        "id": "D4_wGX3_coFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyobraź sobie, że jesteś pracownikiem w firmie sprzedającej kompleksową usługę tworzenia wizerunków medialnych. Oddział, w którym pracujesz obsługuje ważnego klienta działającego w branży gier i usług cyfrowych.\n",
        "\n",
        "Twoim zadaniem jest przygotować model uczenia maszynowego, który określać będzie nastawienie emocjonalne postów z Twittera. Zespół odpowiadający za zbieranie danych właśnie dostarczył zestaw danych dla Ciebie.\n",
        "\n",
        "Do tej pory klasyfikowaniem nastrojów z twittów zajmował się zespół ekspertów. Rozwiązanie takie jest bardzo wolne i drogie, a dokładność ekspertów wynosi tylko 95%. Dlatego zarząd firmy zlecił wdrożenie modelu uczenia maszynowego.\n",
        "\n",
        "Twój model stanowić będzie jedynie część większego produktu oferowanego przez Twoją firmę. Wyniki Twojego modelu będą bezpośrednio wykorzystywane przez następny zespół, którego zadaniem jest przygotować kolejny model uczenia maszynowego przewidujący reakcje opinii publicznej na posty klienta.\n",
        "\n",
        "Prace zespołu, który korzystać będzie z Twojego modelu są już bardzo zaawansowane, dlatego nie może on pozwolić sobie na żadne dodatkowe zmiany w swoim projekcie. Absolutnie konieczne jest, aby Twój model przyporządkowywał posty do jednej z trzech klas 'Positive', 'Negative', 'Neutral' lub analogicznych. Posty nie na temat powinny być klasyfikowane jako 'Neutral'.\n",
        "\n",
        "Notebook z Twoim projektem będzie oglądał Twój szef, więc koniecznie zadbaj, żeby znalazły się w nim najważniejsze przemyślenia, a rysunki były ładne.\n",
        "\n",
        "Powodzenia 🦾"
      ],
      "metadata": {
        "id": "rJlu3kmQchcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polecenia"
      ],
      "metadata": {
        "id": "GRk5odT-VpHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Wstępna obróbka danych:\n",
        "\n",
        " - załaduj zbiór treningowy i testowy,\n",
        " - usuń wiersze o brakujących elementach,\n",
        " - w kolumnie `sentiment` zamień wartości `'Irrelevant'` na `'Neutral'`.\n",
        "\n",
        "1. Wykonaj wizualizacje danych:\n",
        "\n",
        " - histogram tematów twittów (`entity`),\n",
        " - histogram nastawień (`sentiment`),\n",
        " - najczęściej padających słów w treści twittów (`content`).\n",
        "\n",
        "1. Przygotuj dane:\n",
        "\n",
        " - przygotuj zbiór cech poprzez wektoryzacje kolumny `content`, \n",
        " - przygotuj etykiety poprzez zakodowanie tekstowych wartości w kolumnie `sentiment` do postaci liczbowej.\n",
        "\n",
        "  Następnie wytrenuj naiwny model bayesowski. Sprawdź działanie modelu na kilku własnoręcznie napisanych wiadomościach. \n",
        "\n",
        "1. Wytrenuj modele:\n",
        " - naiwny bayesowski,\n",
        " - liniowy SVM,\n",
        " - regresji logistycznej,\n",
        " - drzewo decyzyjne.\n",
        "\n",
        "  Sprawdź model na danych treningowych (walidacja krzyżowa) i testowych, następnie wybierz najlepszy model. Uzasadnij swój wybór.\n",
        "  \n",
        "1. Zespół ekspertów ręcznie klasyfikuje dane z dokładnością 95%. Porównaj z nimi swój model i napisz jakie są przewagi Twojego modelu."
      ],
      "metadata": {
        "id": "Iqep_SopVL6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zbiór danych\n",
        "\n",
        "Zbiór danych został przygotowany na podstawie zbioru [Twitter Sentiment Analysis](https://www.kaggle.com/jp797498e/twitter-entity-sentiment-analysis) i składa się z dwóch plików:\n",
        "-  `twitter_training.csv` - zbiór treningowy,\n",
        "- `twitter_validation.csv` - zbiór testowy.\n",
        "\n",
        "Archiwum z plikami można pobrać z [dysku google](https://drive.google.com/file/d/1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB/view?usp=sharing) lub odkomentowując poniższe linie:"
      ],
      "metadata": {
        "id": "tZpaDghkU_B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install gdown\n",
        "# ! gdown https://drive.google.com/uc?id=1sw2vA87fmAI5V5Xl9k-PCSdN5XwydhOB\n",
        "# ! unzip twitter.zip"
      ],
      "metadata": {
        "id": "VlvbsKdVU0hz"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install wordcloud"
      ],
      "metadata": {
        "id": "95mTOShAjGji"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rozwiązanie"
      ],
      "metadata": {
        "id": "dGrsOK5pT1Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "print('Zainstalowana wersja scikit-learn: {}.'.format(sklearn.__version__))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10) # aby wykresy w Colabie były większe\n",
        "\n",
        "import numpy as np\n",
        "from scipy import diag, interp\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "lQ0m63_gU41z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab65370d-3b47-480e-ef40-932271871dc4"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zainstalowana wersja scikit-learn: 1.0.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('twitter_training.csv')\n",
        "test_data = pd.read_csv('twitter_validation.csv')"
      ],
      "metadata": {
        "id": "h6Ykp7XDRlF5"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Wizualizacja danych\n",
        "\n",
        "# f = sns.countplot(x='sentiment', data=train_data)\n",
        "# h = sns.catplot(y='entity', hue='sentiment', data=train_data, kind='count', height=20, aspect=1)\n",
        "# g = sns.catplot(x='sentiment', col='entity' , col_wrap=4, kind='count', data=train_data, height=4.5, aspect=1.2)\n",
        "\n",
        "# (g.set_axis_labels(\"\", \"Tweet count\")\n",
        "# .set_xticklabels([\"Positive\", \"Neutral\", \"Negative\", 'Irrelevant'])\n",
        "# .set_titles(\"{col_name}\")\n",
        "# .despine(left=True))  "
      ],
      "metadata": {
        "id": "CIIK8rCWZT62"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jak widzimy globalnie (Obrazek 1) klasy są w miare zbalansowane, liczebność nie różni się więcej jak 2-krotnie. W związku z tym wydaje się, że nie ma potrzeby sztucznego wyrównywania ich liczebności i można przejść do dalszego etapu preprocessingu danych"
      ],
      "metadata": {
        "id": "h7rWWbBA9wTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Przydzielamy klasom integerowe labelki\n",
        "\n",
        "# Neutral = Class 0\n",
        "train_data.loc[train_data['sentiment'] == 'Positive', 'sentiment'] = 0\n",
        "# Positive = Class 1\n",
        "train_data.loc[train_data['sentiment'] == 'Neutral', 'sentiment'] = 1\n",
        "# Negative = Class 2\n",
        "train_data.loc[train_data['sentiment'] == 'Negative', 'sentiment'] = 2\n",
        "# Irrelevant = Class 0\n",
        "train_data.loc[train_data['sentiment'] == 'Irrelevant', 'sentiment'] = 0\n",
        "\n",
        "# A teraz to samo dla zbiotu testowego\n",
        "\n",
        "# Neutral = Class 0\n",
        "test_data.loc[test_data['sentiment'] == 'Positive', 'sentiment'] = 0\n",
        "# Positive = Class 1\n",
        "test_data.loc[test_data['sentiment'] == 'Neutral', 'sentiment'] = 1\n",
        "# Negative = Class 2\n",
        "test_data.loc[test_data['sentiment'] == 'Negative', 'sentiment'] = 2\n",
        "# Irrelevant = Class 0\n",
        "test_data.loc[test_data['sentiment'] == 'Irrelevant', 'sentiment'] = 0"
      ],
      "metadata": {
        "id": "aMIHVxWiR4s8"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_data['sentiment'].unique())\n",
        "# print(test_data['sentiment'].unique())"
      ],
      "metadata": {
        "id": "yzBl74otT0E_"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.drop(columns='id')\n",
        "test_data = test_data.drop(columns='id')\n",
        "\n",
        "train_data = train_data.rename(columns={'sentiment':'Class'})\n",
        "test_data = test_data.rename(columns={'sentiment':'Class'})\n",
        "\n",
        "# Pozbywamy się wierszy z niepełnymi informacjani (NaN)\n",
        "train_data = train_data.dropna(axis='rows', how='all', thresh=int(train_data.shape[1]))\n",
        "test_data = test_data.dropna(axis='rows', how='all', thresh=int(test_data.shape[1]))"
      ],
      "metadata": {
        "id": "vYH-7SsoXZy1"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Zobaczmy sobie najczęściej występujące słowa w klasach słów pozytywnych, neutralnych, negatywnych i irrelevant\n",
        "\n",
        "# import wordcloud\n",
        "# from wordcloud import WordCloud\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Neutralne tweety\n",
        "# neutral_list = list(map(str, train_data [train_data['Class'] == 0]['content']))\n",
        "\n",
        "# neutral_words = \" \".join(neutral_list)\n",
        "# neutral_plot = WordCloud(width = 512, height = 512).generate(neutral_words)\n",
        "\n",
        "# # Pozytywne tweety\n",
        "# positive_list = list(map(str, train_data [train_data['Class'] == 1]['content']))\n",
        "\n",
        "# positive_words = \" \".join(positive_list)\n",
        "# positive_plot = WordCloud(width = 512, height = 512).generate(positive_words)\n",
        "\n",
        "# # Negatywne tweety\n",
        "# negative_list = list(map(str, train_data [train_data['Class'] == 2]['content']))\n",
        "\n",
        "# negative_words = \" \".join(negative_list)\n",
        "# negative_plot = WordCloud(width = 512, height = 512).generate(negative_words)\n",
        "\n",
        "# plt.figure(figsize=(10,8))"
      ],
      "metadata": {
        "id": "RfeT0MkjjLdz"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images = [neutral_plot, positive_plot, negative_plot]\n",
        "# image_names = ['neutral', 'positive', 'negative']\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(20,5))\n",
        "# plt.suptitle('Most frequent words in tweets class-wise',y = 0.95, x = 0.4, weight='heavy', size='xx-large')\n",
        "# columns = 4\n",
        "# for i, image in enumerate(images):\n",
        "#     plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "#     plt.axis('off')\n",
        "#     plt.title(image_names[i])\n",
        "#     plt.imshow(image)"
      ],
      "metadata": {
        "id": "Iz2VYWJ-6KzW"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = train_data.drop(columns='Class')\n",
        "y_train = np.asarray(train_data['Class']).reshape(-1, 1).ravel()\n",
        "y_train = y_train.astype('int')\n",
        "\n",
        "X_test = test_data.drop(columns='Class')\n",
        "y_test = np.asarray(test_data['Class']).reshape(-1, 1).ravel()\n",
        "y_test = y_test.astype('int')"
      ],
      "metadata": {
        "id": "aO2ymm3i8gCy"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz jak już mamy zwizualizowane dane, to przekodujmy je na język zrozumiały przez maszynę, tj. wektory cech.\n",
        "\n",
        " W tym celu użyjemy funkcji *CountVectorizer*"
      ],
      "metadata": {
        "id": "lnOPvA2R8q2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['content']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['content']"
      ],
      "metadata": {
        "id": "S-2GLc05AoU4"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych\n",
        "\n",
        "vectorizer_text = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n"
      ],
      "metadata": {
        "id": "BSEn5jw--_rf"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dane treningowe: n_samples: %d, n_features: %d\" % X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW6D6c7Z_ul3",
        "outputId": "9cf9339e-b898-496a-81e7-c87f81c8d298"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dane treningowe: n_samples: 73996, n_features: 31100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Odwrotne mapowanie cech na słowa"
      ],
      "metadata": {
        "id": "Ii78Uj9REIrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)"
      ],
      "metadata": {
        "id": "gPfcl7zBAMT0"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Tworzymy instancję klasyfikatora MultinomialNB"
      ],
      "metadata": {
        "id": "IoZt2KwdE-41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfkvbSoAE9jD",
        "outputId": "e6256042-6048-4740-f525-f92aff67231f"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Sprawdźmy na zbiorze testowym\n",
        "\n",
        "Robimy predykcję dla X_test"
      ],
      "metadata": {
        "id": "Aj7mEw2UGIIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test) # obliczamy predykcję dla tekstów ze zbioru testowego"
      ],
      "metadata": {
        "id": "dVKXffxlGPMk"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nPrecyzja wyliczona built-in method = {}\".format(clf.score(X_test, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2oD875zGjSV",
        "outputId": "3cd78cf7-0d6e-47f2-cc31-2cbb2dc54077"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.831\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       449\n",
            "           1       0.88      0.74      0.80       285\n",
            "           2       0.79      0.82      0.81       266\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.83      0.82      0.82      1000\n",
            "weighted avg       0.83      0.83      0.83      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[402  17  30]\n",
            " [ 48 210  27]\n",
            " [ 34  13 219]]\n",
            "\n",
            "Precyzja wyliczona built-in method = 0.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Możemy nasz klasyfikator ulepszyć, w tym celu trzeba poddać dane stemmingowi"
      ],
      "metadata": {
        "id": "HDYYgsO4HxKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jednak jako, że jedna z naszych kolumn zawiera tylko nazwy gier/tematów o których jest pisane, to stemmingowi chcemy poddać jedynie kolumnę z treścią tweetów, bo to tam szukanie słów o wspólnych korzeniach znaczeniowych będzie mieć znaczenie"
      ],
      "metadata": {
        "id": "jmRzg4o6IVyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importy niezbędnych rzeczy\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Vs0tpuH4R5",
        "outputId": "f3cb937e-b8d0-46c4-878c-d16dff60a70f"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "    return (stemmer.stem(w) for w in analyzer(doc))"
      ],
      "metadata": {
        "id": "dP3zZ0aJKl77"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_train = train_data['entity']\n",
        "contents_train = train_data['content']\n",
        "\n",
        "entities_test = test_data['entity']\n",
        "contents_test = test_data['content']\n",
        "\n",
        "# Dopasowanie i wektoryzowanie dla danych treningowych wraz ze stemmingiem\n",
        "\n",
        "vectorizer_text = CountVectorizer(analyzer=stemmed_words) # stwórz instancje obiektu CountVectorizer dla kodowania tekstu tweetów\n",
        "vectorizer_instances = CountVectorizer() # stwórz instancje obiektu CountVectorizer dla kodowania instancji\n",
        "entities_train = vectorizer_instances.fit_transform(entities_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_train = vectorizer_text.fit_transform(contents_train) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_train = hstack((entities_train, contents_train))\n",
        "\n",
        "# Wektoryzowanie i przetransformowanie danych testowych korzystając ze słownika stworzonego na bazie danych treningowych\n",
        "\n",
        "entities_test = vectorizer_instances.transform(entities_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna instnacji)\n",
        "contents_test = vectorizer_text.transform(contents_test) # naucz vectorizer słownika i przetransformuj dane uczące (kolumna treści)\n",
        "\n",
        "X_test = hstack((entities_test, contents_test))\n",
        "\n",
        "\n",
        "\n",
        "# <--- !! ---> #\n",
        "\n",
        "\n",
        "\n",
        "# # Odwrotne mapowanie tweetów na słowa\n",
        "\n",
        "# Dla kolumny z tekstem tweetów\n",
        "\n",
        "feature_names_text = vectorizer_text.get_feature_names_out()\n",
        "feature_names_text = np.asarray(feature_names_text)\n",
        "\n",
        "# Dla kolumny z tematami\n",
        "\n",
        "feature_names_instances = vectorizer_instances.get_feature_names_out()\n",
        "feature_names_instances = np.asarray(feature_names_instances)\n",
        "\n",
        "\n",
        "\n",
        "# <--- !! ---> #\n",
        "\n",
        "\n",
        "\n",
        "# # # # Klasyfikator\n",
        "\n",
        "# clf = MultinomialNB()\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = clf.predict(X_test)\n",
        "# accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "# print(\"Dokładność: %0.3f\" % accur)\n",
        "# print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "# print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# print(\"Słowa, które z największą pewnością wskazują maszynie, że wiadomość jest pozytywna:\")\n",
        "# top10 = np.argsort(clf.coef_[0])[-10:]\n",
        "# bottom10 = np.argsort(clf.coef_[0])[:10]\n",
        "# print(feature_names_text[top10])\n",
        "\n",
        "# print(\"Słowa najmniej istotne przy klasyfikacji:\")\n",
        "# print(feature_names_text[bottom10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqwF1_TlIIZj",
        "outputId": "ea21a9a0-5df9-440f-fb3a-cc7cb87a10cc"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.797\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       449\n",
            "           1       0.85      0.69      0.76       285\n",
            "           2       0.73      0.79      0.76       266\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.80      0.78      0.79      1000\n",
            "weighted avg       0.80      0.80      0.80      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[389  20  40]\n",
            " [ 51 197  37]\n",
            " [ 40  15 211]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Klasyfikator\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accur = accuracy_score(y_test, y_pred) # dokładność\n",
        "print(\"Dokładność: %0.3f\" % accur)\n",
        "print(\"Classification report:\") # wypisz raport klasyfikacji \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Macierz błędów\") # wypisz macierz (confusion matrix)\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4JJu1XIMFp4",
        "outputId": "79338594-1799-4f56-e056-fd70776cb34a"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność: 0.797\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84       449\n",
            "           1       0.85      0.69      0.76       285\n",
            "           2       0.73      0.79      0.76       266\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.80      0.78      0.79      1000\n",
            "weighted avg       0.80      0.80      0.80      1000\n",
            "\n",
            "Macierz błędów\n",
            "[[389  20  40]\n",
            " [ 51 197  37]\n",
            " [ 40  15 211]]\n"
          ]
        }
      ]
    }
  ]
}